{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from wrangle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up an example scenario as perspective for our regression exercises using the Zillow dataset.\n",
    "\n",
    ">As a Codeup data science graduate, you want to show off your skills to the Zillow data science team in hopes of getting an interview for a position you saw pop up on LinkedIn. You thought it might look impressive to build an end-to-end project in which you use some of their Kaggle data to predict property values using some of their available features; who knows, you might even do some feature engineering to blow them away. Your goal is to predict the values of single unit properties using the obervations from 2017.\n",
    "\n",
    ">In these exercises, you will complete the first step toward the above goal: acquire and prepare the necessary Zillow data from the zillow database in the Codeup database server.\n",
    "\n",
    "1. Acquire bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, and fips from the zillow database for all 'Single Family Residential' properties.\n",
    "\n",
    "2. Using your acquired Zillow data, walk through the summarization and cleaning steps in your wrangle.ipynb file like we did above. You may handle the missing values however you feel is appropriate and meaningful; remember to document your process and decisions using markdown and code commenting where helpful.\n",
    "\n",
    "3. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe with no missing values in your wrangle.py file. Name your final function wrangle_zillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema='zillow'\n",
    "\n",
    "# sql_database_info_probe(schema)\n",
    "\n",
    "\n",
    "# query='''\n",
    "# select * from propertylandusetype\n",
    "\n",
    "\n",
    "# '''\n",
    "# read=pd.read_sql(query, get_db_url(schema))\n",
    "# read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=prep_zillow_2017()\n",
    "\n",
    "df.nunique().sort_values()\n",
    "\n",
    "cols=set(df.columns.to_list())\n",
    "nums=cols-{\n",
    "'fips',                          \n",
    "'bedroomcnt',                   \n",
    "'bathroomcnt',\n",
    "'decade'}\n",
    "cats=cols-nums\n",
    "\n",
    "cols=list(cols)\n",
    "\n",
    "cats=list(cats)\n",
    "nums=list(nums)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows histograms of the categorical data\n",
    "\n",
    "\n",
    "for i in (cats):\n",
    "\n",
    "  \n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.displot(data=df,x=df[i],discrete=True)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in (nums):  \n",
    "#     plt.figure(figsize=(10,6))\n",
    "#     sns.displot(data=df,x=df[i],stat='density',kde=True,discrete=False)\n",
    "    \n",
    "    \n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df1=df.apply(zscore)\n",
    "# df1=df1.apply(abs)\n",
    "# df1=df1.applymap(lambda x: x<1.25 )\n",
    "# df2=df[df1]\n",
    "# df2.nunique(dropna=True)\n",
    "\n",
    "# df2.isna()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this is the future to make categories binned by the z score. Which would be useful to explicitly identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if I should be doing this but it was just to explore the \n",
    "# a=df2.mode(axis=0).values\n",
    "\n",
    "# a=list(a[0])\n",
    "# a=df.mean(axis=0)\n",
    "# vals=dict(zip(cols,a))\n",
    "# vals\n",
    "# df2.fillna(value=vals,inplace=True)   \n",
    "# df2.describe()\n",
    "\n",
    "\n",
    "# df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look at the numerical colums within 1.25 stand deviations\n",
    "# for i in (nums):\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "#     plt.figure(figsize=(10,6))\n",
    "#     sns.displot(data=df2,x=df2[i],stat='density',kde=True,discrete=False)\n",
    "    \n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " >The normalized graphs (commented out for perfomance), skew and kurtosis show we have to consider some outliers in our data likely need to scale to obtain interesting results.\n",
    "\n",
    " >At this step we have simply droped the NAN's as they were a marginal ammount of data and added a categorical colum for decades. The graphs are  for the non categorical cols are not interesting at this step as the highlighted by the extreme skew and kurtosis.\n",
    "\n",
    "\n",
    "  >FIPS (a unique county identifier code) so it might not be useful othere than to clasify which county this was in\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
